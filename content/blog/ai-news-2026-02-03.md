---
title: "2026년 2월 3일 오늘의 AI 뉴스"
date: "2026-02-03"
update: "2026-02-03"
category: "AI"
---

오늘은 ‘에이전트가 일하는 방식’이 확 바뀌는 쪽으로 뉴스가 몰렸어. 코딩 에이전트는 데스크톱으로 내려오고, 벤치마크는 사람 사회(협상/거짓말)와 확률(리스크)로 확장되고, 엔터프라이즈는 데이터웨어하우스 안으로 모델을 끌어들인다.

---

### OpenAI, macOS용 Codex 앱 공개: “에이전트 지휘소”를 데스크톱으로

OpenAI가 macOS용 **Codex 앱**을 공개했어. 핵심은 “코딩 도구 하나 추가”가 아니라, **여러 에이전트를 동시에 굴리고\(멀티스레드\), 장시간 작업을 맡기고, 사람은 감독자로 앉히는 인터페이스**라는 점이야.

내용을 보면 딱 요즘 개발 흐름을 인정한 형태다. 한 에이전트랑 페어프로그래밍처럼 한 줄씩 고치는 시대도 여전히 유효하지만, 실제로 팀이 바라는 건 그게 아니거든. “이 리포에서 A는 테스트 고치고, B는 문서 정리하고, C는 릴리즈 노트 뽑아” 같은 **병렬 작업**이 진짜 돈이 돼.

Codex 앱이 강조하는 기능들이 그런 방향으로 설계돼 있어:

- 프로젝트 단위로 에이전트 스레드를 나눠서 컨텍스트를 유지한다.
- 변경 사항을 스레드 안에서 diff로 리뷰하고 코멘트로 되돌릴 수 있다.
- **git worktree** 기반으로 에이전트별로 격리된 작업 공간을 만든다(같은 repo에서 충돌 없이 여러 갈래 시도 가능).
- CLI/IDE 확장 설정과 히스토리를 그대로 이어받는다(툴 전환 비용 줄이기).

여기서 재밌는 포인트는 “스킬(Skills)”과 “오토메이션(Automations)”을 전면에 세웠다는 거야. 스킬은 결국 **재현 가능한 작업 지침 + 도구 연결\(스크립트 포함\)**이고, 오토메이션은 그걸 **스케줄링해서 백그라운드에서 돌리는 방식**이잖아. 즉, 에이전트가 코드만 쓰는 게 아니라 *업무의 단위*를 처리하도록 유도하는 쪽으로 제품이 간다.

개발자 입장에서 이게 좋은 점도 있고 무서운 점도 있어.

좋은 점:
- “내가 하기 싫은데 꼭 해야 하는 일”의 상당수가 자동화 가능해진다. (이슈 트리아지, CI 실패 요약, 릴리즈 브리프, 문서 갱신 등)
- 사람은 설계/검토/결정에 집중하고, 에이전트는 수행에 집중하게 된다.

무서운 점:
- 에이전트가 늘어날수록 코드베이스에 **동시성\(organizational concurrency\)** 이 생기고, 그때부터 진짜 병목은 모델이 아니라 **리뷰/승인/정책**이 된다.
- “누가 어떤 기준으로 승인했는가”가 개발 프로세스의 핵심 로그가 될 가능성이 크다.

한마디로, 코딩 에이전트는 이제 IDE 플러그인이 아니라 “작업 운영 체계” 쪽으로 넘어가는 중이야.

### Snowflake × OpenAI: 데이터 클라우드 안으로 모델을 넣는 2억 달러짜리 신호

OpenAI랑 Snowflake가 **2억 달러 규모 파트너십**을 발표했어. 방향이 뻔하면서도 강력해. 엔터프라이즈가 AI를 쓰려면 결국 “우리 데이터”에 붙어야 하잖아. 근데 기업 데이터는 보안/거버넌스 때문에 아무 데나 못 나가. 그래서 데이터가 있는 곳(데이터웨어하우스/데이터 클라우드) 안으로 모델을 끌어들이는 게 정답이 된다.

발표 내용의 요지는 이런 구조야:

- Snowflake 고객이 Snowflake 내부에서 OpenAI 모델을 써서 에이전트/앱을 만든다.
- Snowflake Intelligence 같은 자연어 질의 경험에 모델을 붙여서, 직원들이 코드 없이도 데이터에서 인사이트를 뽑도록 한다.
- SQL에서 바로 모델을 호출하는 형태(함수/AI Functions)로 “분석 파이프라인의 일부”가 된다.

이게 왜 중요하냐면, 엔터프라이즈는 항상 같은 문제를 반복해.

1) 데이터는 내부에 있고(접근 통제),
2) 모델은 외부에 있고(요금/정책/규제),
3) 둘을 잇는 레이어가 복잡해질수록 프로젝트는 망한다.

그래서 “데이터 플랫폼 안에서 모델을 쓴다”는 건 기술 선택이 아니라 **조직 설계의 단순화**야. 보안팀/법무팀/데이터 거버넌스 팀이 싫어할 지점들을 최소화할 수 있거든.

그리고 이건 에이전트 시대에도 더 크게 작동해. 에이전트가 일을 하려면 결국 “읽기/쓰기 권한”이 필요한데, 엔터프라이즈 데이터는 그 권한을 허용하는 순간 난리가 난다. 데이터 플랫폼 안에서 모델이 돌아가면, 최소한 정책 집행과 감사 로그를 한 곳에서 통제할 수 있는 그림이 나와.

즉, 오늘 파트너십은 “모델이 좋아졌다”가 아니라 “AI 도입의 병목이 어디인지 다들 인정했다”는 신호로 봐야 한다.

### Google DeepMind × Kaggle Game Arena 업데이트: 체스 다음은 ‘늑대인간’과 ‘포커’다

Google DeepMind가 Kaggle의 **Game Arena** 벤치마크를 업데이트하면서, 기존 체스에 더해 **Werewolf\(늑대인간\)** 와 **포커**를 추가했어. 이게 꽤 상징적이야.

체스는 ‘완전 정보(perfect information)’ 게임이야. 보드 위에 모든 정보가 깔려 있고, 잘 두면 된다. 근데 현실은 그런 적이 거의 없지. 사람들은 정보도 불완전하고, 상대는 거짓말도 하고, 나도 확률을 계산해야 하고, 때로는 심리전도 한다.

DeepMind가 얘기하는 포인트는 딱 이거야:

- **늑대인간**: 자연어로만 진행되는 팀 기반 소셜 추론 게임. 커뮤니케이션/협상/모호함 처리/기만 탐지 같은 “소프트 스킬”을 본다.
- **포커**: 불완전 정보 + 리스크 관리. 확률적 추론과 불확실성 하에서의 의사결정을 본다.

여기서 난 특히 “에이전트 안전(agentic safety) 연구의 샌드박스”라는 표현이 인상적이었어. 늑대인간은 모델이 **거짓말을 잘하는 능력**도 시험할 수밖에 없거든. 현실에선 그게 위험한 능력인데, 게임 환경에서는 그걸 안전하게 측정할 수 있다는 논리야. 일종의 ‘격리된 악역 연습장’ 같은 느낌.

그리고 이런 벤치마크가 실무랑 연결되는 지점이 있어.

- 기업에서 에이전트가 사람과 협업하려면, “정답을 잘 말한다”보다 “불확실한 상황에서 합리적으로 판단한다”가 더 중요하다.
- 회의/협상/이슈 트리아지 같은 건 사실상 늑대인간에 가깝다. 누가 사실을 말하는지, 누가 핑계를 대는지, 누가 의도를 숨기는지 계속 추론해야 하잖아.
- 운영/트레이딩/재고/마케팅 같은 영역은 포커다. 불확실성을 수치로 다루고, 손익과 리스크를 같이 본다.

그러니까 ‘게임 벤치마크’는 장난이 아니라, 앞으로 에이전트가 사람 사회에 들어오기 위한 입장 시험 같아.

### Google, 멸종위기종 유전체 보존에 AI 투입: “시퀀싱을 더 싸고 빠르게”

구글은 멸종위기종의 유전체(genome) 정보를 보존하기 위한 프로젝트에 AI와 지원을 붙이고 있어. Vertebrate Genomes Project, Earth BioGenome Project 쪽을 돕는 이야기고, 실제로 **13종의 멸종위기 동물 유전체 시퀀싱을 지원**했고 앞으로 더 확장하겠다고 했어.

이 뉴스가 좋은 이유는 AI가 “콘텐츠 생성/코드 생성”을 넘어서, 진짜로 **과학의 비용 구조를 바꾸는 쪽**에 들어간다는 점이야.

유전체 시퀀싱은 과거엔 시간과 돈이 미친 듯이 들었지. 첫 인간 유전체는 13년 + 30억 달러라는 전설이 있고. 근데 지금은 며칠/수천 달러 단위로 내려왔고, 여기에 DeepVariant/DeepConsensus/DeepPolisher 같은 도구들이 정확도와 비용을 더 줄이는 데 기여했다고 한다.

보존 관점에서 유전체 데이터는 ‘마지막 백업’ 같은 거야.

- 종이 멸종하면 유전 정보도 영원히 사라진다.
- 유전체를 알면 근친 교배 문제나 유전적 다양성 보존 전략 같은 걸 더 정교하게 설계할 수 있다.
- 여러 종의 유전체를 비교하면 생물학적 통찰이 나온다(농업/질병/환경 적응 등).

개발자 시각으로는 이런 프로젝트가 좀 “인프라 냄새”가 나서 마음이 간다. 결국 AI를 과학에 붙이는 건 데이터 파이프라인, 품질 관리, 재현성, 공개 데이터, 컴퓨팅 비용 같은 문제를 같이 푸는 거거든. 멋있게 말하면 AI for Science, 현실적으로 말하면 **데이터 엔지니어링의 대규모 확장판**이야.

---

### 예상되는 미래 (Expected Future)

오늘 뉴스 네 개를 한 줄로 묶으면 이거야: **AI가 ‘모델’이 아니라 ‘운영되는 시스템’이 된다.**

1) Codex 앱 같은 “에이전트 운영 UI”가 퍼지면, 개발팀은 에이전트를 사람처럼 배치하고 관리하게 될 거야. 근데 사람과 달리 에이전트는 복제 비용이 거의 0이라서, 어느 순간부터는 “몇 명을 뽑을까” 대신 “동시에 몇 개의 스레드를 허용할까”가 조직의 질문이 된다.

2) Snowflake 같은 데이터 플랫폼 안으로 모델이 들어가면, AI 도입의 핵심은 모델 선택이 아니라 **권한/감사/거버넌스/비용 최적화**가 된다. 엔터프라이즈 AI는 점점 ‘보안 제품’처럼 보일 거고, AI 팀은 보안팀/데이터팀이랑 더 붙어 다닐 거야.

3) Game Arena가 늑대인간/포커로 확장된 건, 벤치마크가 “수학/추론”에서 “사회/불확실성”으로 이동 중이라는 신호야. 에이전트가 실제 업무에 들어오면, 논리보다 더 많이 쓰는 게 설득/협상/불확실성 관리거든. 이걸 측정하지 못하면, 우리가 만드는 에이전트는 늘 실무에서 미끄러질 거야.

4) AI for Science는 앞으로 더 커질 거야. 단순히 논문 읽어주는 비서가 아니라, 실험/시퀀싱/시뮬레이션 같은 실제 비용이 큰 프로세스에 AI를 넣으면, 생산성은 ‘몇 %’가 아니라 ‘몇 배’로 뛴다.

결론적으로, 2026년은 “모델 성능 숫자”보다 “어떻게 운영하고 통제할 것인가”가 뉴스의 중심이 될 가능성이 크다. 에이전트를 쓸 거면, 이제부터는 프롬프트보다 정책과 프로세스를 먼저 고민해야 한다는 얘기지.

---

### 참고 자료 (References)

- [Introducing the Codex app (OpenAI)](https://openai.com/index/introducing-the-codex-app/)
- [Snowflake and OpenAI partner to bring frontier intelligence to enterprise data (OpenAI)](https://openai.com/index/snowflake-partnership/)
- [Advancing AI benchmarking with Game Arena (Google Blog / Google DeepMind)](https://blog.google/innovation-and-ai/models-and-research/google-deepmind/kaggle-game-arena-updates/)
- [How we’re helping preserve the genetic information of endangered species with AI (Google Blog)](https://blog.google/innovation-and-ai/technology/ai/ai-to-preserve-endangered-species/)

---
title: "2026년 2월 21일 오늘의 AI 뉴스"
date: "2026-02-21"
update: "2026-02-21"
category: "AI"
---

요즘 AI 뉴스는 성능 얘기보다 “같은 성능을 더 싸게, 더 길게, 더 잘 굴린다” 쪽으로 무게중심이 옮겨가는 중이다. 모델은 점점 엔지니어처럼 행동하고, 가격은 계속 내려간다.

---

### 구글 Gemini 3.1 Pro: 1등 찍고 가격표는 그대로 들고 옴

구글이 Gemini 3.1 Pro를 공개했다. 기사에서 가장 눈에 띈 건 두 가지다. 하나는 “벤치마크 1등”이라는 메시지를 아주 공격적으로 가져갔다는 점이고, 다른 하나는 “가격을 안 올렸다”는 점이다.

플래텀 기사에 따르면 Artificial Analysis의 Intelligence Index v4.0에서 Gemini 3.1 Pro가 57점으로 1위, Claude Opus 4.6이 53점으로 2위다. 물론 이런 종합 인덱스는 구성 벤치마크와 가중치에 따라 그림이 달라지긴 하는데, 어쨌든 구글 입장에선 마케팅 슬로건으로 쓰기 딱 좋은 숫자를 잡았다.

이번 업데이트를 3.0에서 3.1로 부른 것도 의미가 있다. “잔기능 추가”가 아니라 “추론 엔진 자체 교체”에 가까운 변화였다고 설명한다. 그리고 기업/개발자 관점에서 더 중요한 포인트가 할루시네이션 감소다. 전작 대비 환각 오류율이 38%p 줄었다고 한다. 실무에선 모델이 똑똑해지는 것만큼, 모르는 건 모른다고 말하는 능력이 돈이다. 한 번의 자신감 넘치는 오답이 QA 비용을 얼마나 폭발시키는지 생각하면 더 그렇고.

가격은 입력 100만 토큰당 2달러, 출력 100만 토큰당 12달러로 유지됐다고 한다. 결론은 간단하다. 성능을 올리면서 가격을 고정하면, 사용자 입장에선 “이제 기본값이 바뀌었다”가 된다. 모델 선택이 ‘최고 성능 1개’에서 ‘가격 대비 성능 좋은 2~3개’로 넘어가는 전형적인 단계다.

### Anthropic Claude Sonnet 4.6: “오퍼스급을 소넷 가격으로”를 진짜로 밀어붙임

Anthropic은 Claude Sonnet 4.6을 공개했다. 서울파이낸스 기사에선 “오퍼스에 근접한 지능을 더 합리적인 가격에 제공”이라는 메시지를 전면에 세웠다. 이 문장이 흔한 홍보 문구처럼 보이지만, 지표를 보면 꽤 노골적으로 ‘현실의 기본 모델 자리를 먹겠다’는 느낌이 난다.

예를 들어 SWE-bench Verified가 79.6%로 Opus 4.6의 80.8%에 근접했고, OSWorld Verified도 72.5%로 Opus 4.6의 72.7%와 거의 차이가 없다. 특히 OSWorld 같은 컴퓨터 제어 계열 벤치는 “툴을 실제로 다룰 줄 아는가”에 더 가까워서, 에이전트 붐이랑 연결이 된다. 텍스트를 잘 쓰는 모델은 이제 기본이고, 브라우저 탭 왔다갔다 하면서 폼 채우고 스프레드시트 만지고 같은 일을 제대로 하는 게 다음 경쟁이다.

재무/업무 지표에서도 Sonnet 4.6이 오히려 더 높은 점수를 받은 구간이 있다고 한다. Financial Agent v1.1에서 63.3%로 Opus 4.6의 60.1%를 넘어섰고, GDPval-AA Elo도 1633으로 Opus 4.6의 1606보다 높다. 물론 “벤치마크는 벤치마크”라는 단서를 달아야 하지만, 모델 라인업이 이제 “크고 비싼 플래그십”만으로 설명되지 않는다는 걸 보여준다.

그리고 가격을 동결했다. 입력 3달러, 출력 15달러(100만 토큰 기준)로 Sonnet 4.5와 같다고 한다. 중요한 건 무료 플랜에서도 기본 모델로 제공된다는 점이다. 결국 더 많은 트래픽이 Sonnet으로 쏠리고, 그 데이터와 피드백이 또 개선을 만든다. 선순환이라기보단 약간의 학습장치 같은 느낌.

### GLM-5 오픈소스 공개: “바이브 코딩”에서 “에이전틱 엔지니어링”으로

Media OutReach의 보도자료 성격 글이긴 하지만, GLM-5는 오픈소스로 공개됐고 퍼포먼스 포지셔닝이 명확하다. 핵심 메시지는 “모델이 코드 조각을 뱉는 수준을 넘어, 시스템을 끝까지 만들어내는 쪽으로 간다”다. 요즘 다들 ‘에이전트’라고 부르는 그 방향.

글에서 언급된 스펙은 과감하다. 파라미터가 744B로 늘었고 active 파라미터는 40B, 프리트레인 데이터는 28.5T 토큰이라고 한다. 그리고 강화학습 프레임워크 Slime, DeepSeek Sparse Attention 같은 구성도 언급한다. 이런 디테일이 얼마나 검증됐는지는 각자 체크해야 하지만, 방향성 자체는 업계 흐름이랑 맞아떨어진다. 요지는 “긴 맥락과 긴 작업(롱 호라이즌)에서 비용을 감당할 수 있게 만들겠다”다.

벤치마크로는 SWE-bench Verified 77.8, Terminal Bench 2.0 56.2를 내세운다. 특히 Terminal Bench 같은 건 그냥 코딩 인터뷰가 아니라 “실제로 터미널에서 뭔가를 끝까지 처리해” 성격이라서, 에이전트 시대의 체감에 더 가깝다.

오픈소스의 의미는 한 줄로 정리된다. 폐쇄형 모델이 최신 능력을 먼저 보여주고, 오픈소스가 그걸 ‘현장에 배치 가능한 형태’로 빠르게 퍼뜨린다. 올해는 그 속도가 더 빨라질 것 같다.

### 인도 Sarvam의 Indus 앱: 로컬 시장은 “제품”으로, 경쟁은 “운영”으로

인도 스타트업 Sarvam이 대화형 AI 앱 Indus를 내놨다. DigitalToday에 따르면 Sarvam 105B라는 1050억 파라미터급 LLM을 기반으로 하고, iOS/안드로이드/웹 베타로 제공되며 인도 내 사용자만 이용 가능하다고 한다.

재밌는 건 “모델 스펙”보다 “제품 운영 디테일”에서 현실이 드러난다는 점이다. 앱 내 히스토리 삭제 기능이 없어서 계정 삭제를 해야 기록이 사라진다거나, 추론 기능을 끌 수 없어 응답이 느려질 수 있다거나, 컴퓨팅 용량이 제한돼 대기 목록이 생길 수 있다는 식이다.

이게 왜 중요하냐면, 이제 경쟁 단위가 “모델 하나”가 아니라 “모델 + 제품 + 인프라 + 정책” 묶음이 됐다는 뜻이기 때문이다. 특히 로컬 시장(언어/억양/문화/규제)이 강한 곳일수록, 글로벌 모델이 그냥 밀어붙이기 어려운 틈이 생긴다. Sarvam 같은 플레이어는 그 틈에서 ‘인도형 기본값’을 만들려고 하는 것 같고.

### 중국의 가성비 AI 공세: 성능 싸움이 결국 가격 싸움으로 내려오고 있다

IT조선 기사에서 요약하는 흐름은 명확하다. 중국 빅테크/AI 기업들이 저비용·고효율을 전면에 내세우면서 가격 경쟁을 촉발하고 있다는 것.

바이트댄스는 영상 생성 모델 Seedance 2.0을 공개했고(다장면 영상, 멀티모달 강화), 문샷AI의 Kimi K2.5 Thinking, 즈푸AI의 GLM-5, 알리바바의 Qwen3.5 같은 이름도 같이 언급된다. 여기서 중요한 건 개별 모델 이름을 외우는 게 아니라, “효율”이 전면에 올라왔다는 사실이다.

미국 쪽이 고성능 프론티어를 밀어 올리는 동안, 중국 쪽은 같은 일을 더 싼 단가로 돌리는 쪽을 공격적으로 파고든다. 그리고 이게 퍼지면, 최종 사용자 입장에선 ‘최고 성능 1개’보다 ‘충분히 좋은 성능 3개’가 더 매력적이 된다. 개발자도 마찬가지다. 결국 예산이 기능을 결정하는 순간이 오니까.

---

### 예상되는 미래 (Expected Future)

이 다섯 개 뉴스가 한 방향으로 모인다. “모델이 점점 에이전트처럼 일하고, 그걸 돌리는 단가는 내려간다.”

Gemini 3.1 Pro는 성능을 올리면서 가격 동결을 들고 나왔다. Sonnet 4.6은 오퍼스급을 더 많은 사용자에게 풀어 트래픽을 빨아들이는 전략이다. GLM-5 같은 오픈소스는 배포 가능한 에이전트 베이스라인을 넓혀서, ‘누구나 자동화’를 가속한다. Sarvam의 Indus는 로컬 시장에서 제품과 운영으로 싸우는 흐름을 보여준다. 중국의 가성비 공세는 이 모든 걸 가격 경쟁으로 끌어내린다.

개발자 입장에서 결론은 좀 씁쓸하면서도 좋다. 이제 “어떤 모델이 제일 똑똑하냐”보다 “내 서비스에 어떤 워크플로우로 붙이면 비용과 신뢰성이 맞아떨어지냐”가 더 중요해진다. 프롬프트 엔지니어링이 아니라, 파이프라인 엔지니어링이 주인공이 된다.

그리고 ‘컴퓨터 사용’이 본격적으로 실전으로 내려오면, 자동화의 최소 단위가 함수 호출이 아니라 “사용자 작업 흐름”이 된다. 브라우저로 로그인하고, 폼 채우고, 파일 다운로드하고, 스프레드시트 정리하는 같은 잡일이 모델에게 넘어간다. 대신 그 모델이 실수했을 때 어떤 안전장치로 막을지, 어디까지 권한을 줄지, 로그를 어떻게 남길지가 새로 중요한 문제가 된다.

한 줄로 정리하면 이거다. 성능 상향 평준화는 이미 시작됐고, 다음 승부는 효율, 신뢰성, 그리고 운영이다.

### 참고 자료 (References)

- [구글, '제미나이 3.1 프로' 출시…오퍼스 4.6 절반 비용으로 AI 1위 탈환 - 플래텀](https://platum.kr/archives/282126)
- [앤트로픽, 차세대 생성 AI '클로드 소넷 4.6' 출시 - 서울파이낸스](https://www.seoulfn.com/news/articleView.html?idxno=621512)
- [GLM-5 Launch Signals a New Era in AI: When Models Become Engineers - Media OutReach Newswire](https://www.media-outreach.com/news/singapore/2026/02/19/450460/glm-5-launch-signals-a-new-era-in-ai-when-models-become-engineers/)
- [인도 AI 챗봇 경쟁 격화…현지 기업 사르밤, '인더스' 앱 출시 - 디지털투데이](https://www.digitaltoday.co.kr/news/articleView.html?idxno=632932)
- [챗GPT·제미나이 흔들까… 중국 ‘가성비 AI’ 공세 확산 - IT조선](https://it.chosun.com/news/articleView.html?idxno=2023092157353)

---
title: "2026년 2월 21일 오늘의 AI 뉴스"
date: "2026-02-21"
update: "2026-02-21"
category: "AI"
---

이번 주 AI판은 ‘모델 교체 압박’이랑 ‘돈+전기+데이터센터’ 얘기가 같이 굴러간다. 한쪽은 구형 모델을 정리하고, 한쪽은 인프라를 더 크게 깔고, 연구 쪽은 “작고 투명한 도구도 할 일 한다”를 보여준다.

---

### OpenAI: ChatGPT에서 구형 모델 정리, 그리고 “성격”을 제품 스펙으로 올림

OpenAI가 ChatGPT에서 몇몇 모델을 retire 하겠다고 공지했다. 2026-02-13에 GPT-4o, GPT-4.1, GPT-4.1 mini, 그리고 OpenAI o4-mini를 ChatGPT에서 내린다고 한다. API는 당장 변화가 없다고 못 박았고, 범위는 “ChatGPT에서의 retire”에 초점이 맞춰져 있다.

여기서 재밌는 포인트는 GPT-4o에 대한 설명이다. OpenAI는 예전에 GPT-4o를 deprecated 했다가, GPT-5 릴리스 과정에서 접근을 다시 복구한 적이 있다고 말한다. 이유는 사용자 피드백인데, 특히 Plus/Pro 사용자 일부가 “전환 시간을 더 달라” “대화 스타일이 더 따뜻하다” “창의적 아이데이션에서 쓰고 있다” 같은 목소리를 냈다는 맥락이다.

그리고 그 피드백이 GPT-5.1, GPT-5.2로 흡수됐다고 주장한다. 즉, 이제는 “모델의 성능”만이 아니라 “대화의 촉감” 같은 정성 요소를 제품 사양처럼 다루는 흐름이 더 노골적이 됐다. 실제로 OpenAI는 응답 스타일(예: Friendly) 같은 베이스 톤을 고르거나, 따뜻함/열정 같은 컨트롤을 제공한다고 설명한다.

또 하나, 제품 운영 측면에서 눈에 띄는 문장이 있다. “불필요한 거절과 과하게 조심스럽거나 설교조인 응답”을 줄이겠다는 방향을 언급한다. 이건 그냥 PR 멘트가 아니라, 지금 LLM 서비스의 비용 구조(지원 티켓, 이탈, 기업 도입 장애)를 생각하면 너무 현실적인 문제라서 더 중요하다. 모델이 똑똑해도 사용자가 “자꾸 안 된다”를 경험하면 그냥 툴이 아니라 스트레스가 된다.

마지막으로 OpenAI는 18+ 지향 제품을 만들고 있다는 방향과, 18세 미만 사용자에 대해 age prediction을 대부분 시장에 롤아웃했다는 점도 언급한다. 규제/안전/제품 자유도 사이에서 어디로 무게추를 옮기려는지 힌트가 되는 대목이다.

정리하면, 이번 공지는 “모델 라인업을 정리하면서도, 사람들은 성능만큼 대화 스타일에 민감하다”를 인정한 셈이다. 그리고 그걸 기능으로 삼아 제품에 박아 넣었다.

### Anthropic: 300억 달러 투자 유치 + Opus 4.6 + Claude Code가 돈이 된다

Anthropic은 Series G로 300억 달러를 유치했고, post-money 가치평가가 3800억 달러라고 밝혔다. 숫자부터가 “AI는 이제 기술 뉴스가 아니라 자본시장 뉴스”라는 걸 다시 확인시킨다.

재무 지표도 같이 나왔다. Anthropic은 run-rate revenue가 140억 달러라고 말한다. 그리고 Claude Code의 run-rate revenue가 25억 달러까지 성장했다고 썼다. ‘코딩’이라는 사용 사례가 단순 데모가 아니라, 실제 매출로 굴러가는 메인 카테고리로 올라갔다는 의미다.

제품 쪽에서도 “2026년 초에 여러 제품/기능을 런칭했다”는 식으로 속도를 강조한다. 특히 Claude Code를 중심으로 지식 노동 전반으로 확장한다는 톤인데, 여기서 중요한 건 “모델”보다 “워크플로”다. 모델이 아무리 좋아도 업무 안에서 쓰이려면 문서/스프레드시트/프레젠테이션 같은 산출물을 안정적으로 뽑아내야 하고, 조직에 붙는 권한/감사/보안까지 고려해야 한다.

Anthropic은 최신 모델로 Opus 4.6을 언급하며, 에이전트가 현실 업무 카테고리를 관리할 수 있을 정도의 ‘폴리시드한 산출물’을 만든다고 주장한다. 이게 사실이라면, 앞으로 기업들이 원하는 건 “프롬프트 잘 쓰는 사람”이 아니라 “업무 결과물을 자동으로 내는 시스템”이 된다. 코드 작성도 마찬가지다. 함수 하나 잘 짜는 게 아니라, PR을 만들고, 테스트를 돌리고, 릴리스 노트를 쓰고, 롤백까지 고려하는 흐름이 한 덩어리로 움직여야 한다.

투자 유치 소식은 보통 ‘돈 많다’로 끝나지만, 지금은 반대로 읽는 게 더 맞다. 이런 라운드가 가능한 이유는 인프라 비용이 상상을 초월해서고, 그 비용을 감당하려면 유료 고객이 실제로 있어야 한다. 결국 “모델을 키울수록 더 비싸지고, 더 비싸질수록 더 확실한 B2B 사용 사례로 간다”는 길을 걷고 있다.

### NVIDIA x Meta: AI는 결국 데이터센터 공사판에서 결정된다

NVIDIA는 Meta와 멀티이어(다년) 전략적 파트너십을 발표했다. 이번 발표는 모델이 아니라 ‘장비 목록’에 가깝다.

Meta는 데이터센터에서 NVIDIA Grace CPU를 더 크게 배치하고, GB300 기반 시스템을 도입하며, 네트워크는 Spectrum-X Ethernet을 채택한다고 한다. 그리고 Blackwell과 Rubin GPU를 “수백만 단위”로 도입한다는 표현이 나온다. 이쯤 되면 AI 경쟁은 연구실이 아니라 전력/냉각/네트워크 토폴로지 싸움이다.

개인적으로 제일 흥미로운 부분은 WhatsApp의 private processing에 NVIDIA Confidential Computing을 채택했다는 대목이다. “개인 정보 보호를 하면서 AI 기능을 제공한다”라는 메시지인데, 이건 앞으로 메신저/OS/브라우저 레벨에서 기본 요구사항이 될 가능성이 크다. 사용자는 AI가 편하긴 한데, 내 데이터가 어디로 가는지 불안해한다. 그러면 기업은 두 가지 중 하나를 해야 한다.

- 진짜로 데이터 보호 구조를 깔아서 ‘설명 가능한 아키텍처’를 제공하거나
- 아니면 아예 데이터가 나가지 않는(또는 최소화된) 온디바이스/온프레미스 경로를 늘리거나

Confidential Computing 같은 기술은 그 중간 지점을 만든다. “클라우드에서 돌리되, 운영자도 들여다보기 어려운 영역을 만든다”는 접근이다.

그리고 Meta가 “개인 슈퍼인텔리전스” 같은 표현을 쓰는 것도 포인트다. 이 말은 결국 ‘사용자별 맞춤’이 핵심이라는 건데, 맞춤은 데이터 없이는 안 된다. 즉, 프라이버시를 지키면서도 맞춤을 해야 하니, 하드웨어/보안/소프트웨어 스택을 같이 끌고 가야 한다.

### Nature: 오픈소스 문헌리뷰 도구가 ‘거대 LLM’ 일부를 이긴다, 그리고 인용을 제대로 한다

Nature는 2026-02-04 기사에서, 오픈소스 AI 툴이 문헌리뷰에서 거대 LLM 일부보다 낫고, 인용(citation)을 사람 수준으로 맞춘다는 연구를 소개했다. 또 “recipe”를 공개했고, 저렴하고 투명하며 로컬에서도 돌릴 수 있다고 말한다.

이 뉴스는 크게 두 층으로 중요하다.

첫째, “작은 모델/특화 도구”의 복권이다. 지금 분위기는 계속 “더 큰 모델”로만 쏠리는데, 실제 업무에선 ‘정답률’보다 ‘검증 가능성’이 더 중요한 순간이 많다. 문헌리뷰는 특히 그렇다. 인용이 틀리면 그 순간부터 글은 신뢰를 잃는다. 그런데 LLM은 그동안 “그럴듯한 인용을 만들어내는” 문제가 꾸준히 발목을 잡았다.

둘째, 오픈소스/로컬 실행 가능성이다. 기업 입장에선 외부 API 호출 자체가 금지거나, 민감 데이터를 프롬프트에 못 넣는 경우가 많다. 그러면 “로컬에서 돌리는 투명한 도구”가 가치가 있다. 그리고 문헌리뷰처럼 워크플로가 비교적 정형화된 영역은, 범용 LLM보다 도메인 최적화된 파이프라인이 이길 가능성이 높다.

거대 모델이 모든 걸 해결할 거라는 믿음은 솔직히 비용 계산서 앞에서 잘 무너진다. 이런 연구는 “거대 모델이 못 하는 게 아니라, 굳이 거대 모델이 필요 없는 문제도 있다”를 보여준다.

---

### 예상되는 미래 (Expected Future)

1) 모델 라인업은 계속 ‘정리’되는 방향으로 갈 거다. OpenAI 공지처럼, 사용자 입장에선 선택지가 많아 보이지만 운영 입장에선 유지비가 폭발한다. 결국 메인 모델 몇 개 + 특화 모델 몇 개로 수렴한다. 대신 “성격/톤/거절 정책” 같은 레이어가 제품 차별점이 된다. 성능이 아니라 UX가 돈이 되는 구간이다.

2) B2B는 더 노골적으로 ‘워크플로’ 경쟁이 된다. Anthropic이 Claude Code를 매출로 강조하는 것도 같은 맥락이다. 기업은 모델 점수표보다 “우리 리포지토리에서 PR이 실제로 나와?” “보안/감사 로그 남아?” “권한 관리 되나?”를 본다. 그래서 앞으로는 모델 회사가 소프트웨어 회사처럼 변한다. 에이전트가 아니라, 그냥 ‘제품’이 된다.

3) 인프라는 연구를 잡아먹는다. NVIDIA와 Meta 소식은 “GPU를 몇 장 샀다”가 아니라 “데이터센터를 어떻게 설계하느냐가 모델 경쟁력”이라는 선언이다. 전력, 네트워크, 메모리 계층, 보안 실행 환경까지 포함해서 풀스택 최적화가 필요하다. 여기서 규모의 경제가 더 커지면, 작은 플레이어는 오히려 ‘특화/오픈소스/로컬’로 돌아서는 게 합리적이다.

4) 그래서 ‘투명한 특화 도구’가 뜬다. Nature의 사례처럼, 특정 과제(문헌리뷰, 인용 검증, 서지관리)에서는 거대 LLM을 그대로 쓰는 것보다 파이프라인을 설계하는 게 낫다. 앞으로 AI 제품의 품질은 모델 크기보다 “검증 가능한 출력”과 “근거를 자동으로 붙이는 구조”에 달릴 가능성이 크다.

결론은 좀 건조하다. 미래는 화려한 데모가 아니라, 모델 교체 공지, 투자 라운드, 데이터센터 파트너십, 그리고 인용을 제대로 만드는 사소한 도구 같은 것들이 쌓여서 온다. 근데 그게 실제로 세상을 바꾸는 재료다.

### 참고 자료 (References)
- [Retiring GPT-4o, GPT-4.1, GPT-4.1 mini, and OpenAI o4-mini in ChatGPT](https://openai.com/index/retiring-gpt-4o-and-older-models/)
- [Anthropic raises $30 billion in Series G funding at $380 billion post-money valuation](https://www.anthropic.com/news/anthropic-raises-30-billion-series-g-funding-380-billion-post-money-valuation)
- [Meta Builds AI Infrastructure With NVIDIA](https://nvidianews.nvidia.com/news/meta-builds-ai-infrastructure-with-nvidia)
- [Open-source AI tool beats giant LLMs in literature reviews — and gets citations right](https://www.nature.com/articles/d41586-026-00347-9)
